{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPO+UfTrrMizbGWLickLazf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jakless/mgr2024/blob/main/Model_20240504v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ROZPAKOWYWANIE**"
      ],
      "metadata": {
        "id": "DXoSztcS8H54"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Q4OwPHVN6GTU"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "def unzip_file(zip_file_path, extract_to_path):\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to_path)\n",
        "\n",
        "# Przykładowe użycie funkcji:\n",
        "zip_file_path = '/content/images.zip'\n",
        "extract_to_path = '/content'\n",
        "unzip_file(zip_file_path, extract_to_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **USUWANIE ELEMENTÓW FOLDERU**"
      ],
      "metadata": {
        "id": "kSQpneKq8NCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Ścieżka do folderu, który chcemy oczyścić\n",
        "folder_path = '/content/predictions'\n",
        "\n",
        "# Usunięcie wszystkich plików z folderu\n",
        "for filename in os.listdir(folder_path):\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "    try:\n",
        "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "            os.unlink(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "            os.rmdir(file_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to delete {file_path}. Reason: {e}\")\n"
      ],
      "metadata": {
        "id": "_KztYVHD8RFx"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. WCZYTANIE MODELU**"
      ],
      "metadata": {
        "id": "IUqt-egTqcsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "# Wczytanie wytrenowanego modelu\n",
        "model = load_model(\"efficientnet_model.h5\")\n",
        "\n",
        "# Funkcja do przetwarzania obrazu\n",
        "def preprocess_image(image_path):\n",
        "    # Wczytanie obrazu\n",
        "    image = load_img(image_path, target_size=(224, 224))\n",
        "    image = img_to_array(image)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    # Przetworzenie obrazu do formatu akceptowanego przez model EfficientNet\n",
        "    image = preprocess_input(image)\n",
        "\n",
        "    return image\n",
        "\n",
        "# Wczytanie obrazu do przetwarzania\n",
        "image_path = '/content/images/train/zdjecie1.jpg'  # Zmień na ścieżkę do swojego obrazu\n",
        "image = preprocess_image(image_path)\n",
        "\n",
        "# Przewidywanie etykiet dla obrazu\n",
        "predictions = model.predict(image)\n",
        "\n",
        "# Określenie progu dla prawdopodobieństwa\n",
        "threshold = 0.5\n",
        "\n",
        "# Wyświetlanie wyników przewidywań\n",
        "print(\"Wyniki przewidywań:\")\n",
        "print(predictions)\n",
        "\n",
        "# Wczytanie obrazu do wyświetlenia\n",
        "image_display = cv2.imread(image_path)\n",
        "image_display = cv2.cvtColor(image_display, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Znalezienie obszaru z najwyższym prawdopodobieństwem dla klasy \"GREY\"\n",
        "grey_class_index = label_encoder.index('GREY')\n",
        "grey_class_activation = model.layers[-2].output[:, grey_class_index]\n",
        "\n",
        "# Znalezienie współrzędnych maksymalnej aktywacji\n",
        "activation_map = tf.squeeze(grey_class_activation)\n",
        "activation_map = tf.nn.max_pool2d(activation_map[None,None,...], 10, 1, padding='SAME')\n",
        "\n",
        "# Utworzenie funkcji TensorFlow\n",
        "@tf.function\n",
        "def get_activation_map_value():\n",
        "    return activation_map\n",
        "\n",
        "# Pobranie wartości tensora w kontekście TensorFlow\n",
        "activation_map_value = get_activation_map_value()\n",
        "\n",
        "# Znalezienie współrzędnych maksymalnej aktywacji\n",
        "ymax, xmax = np.unravel_index(np.argmax(np.reshape(activation_map_value, (-1,))), activation_map_value.shape[1:])\n",
        "xmin, ymin = xmax - 224, ymax - 224  # Oblicz współrzędne rogu górnego lewego\n",
        "\n",
        "# Wydrukuj lokalizację wykrytego elementu \"GREY\"\n",
        "print(f\"Współrzędne dla GREY: (xmin={xmin}, ymin={ymin}), (xmax={xmax}, ymax={ymax})\")\n",
        "\n",
        "# Zaznaczenie wykrytego obiektu za pomocą prostokąta\n",
        "cv2.rectangle(image_display, (xmin, ymin), (xmax, ymax), (255, 0, 0), 2)\n",
        "\n",
        "# Wyświetlenie obrazu\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(image_display)\n"
      ],
      "metadata": {
        "id": "e6fP01rHqgRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ================================================================================"
      ],
      "metadata": {
        "id": "YW3e6Qo4yqZR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. KOD WYSZUKUJĄCY WSZYSTKIE ETYKIETY I ELEMENTY**"
      ],
      "metadata": {
        "id": "ggDXpRH4yudx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Accuracy: 0.38 Precision: 1.0 Recall: 0.38 F1 Score: 0.55 Confusion Matrix:[[19 31][ 0  0]]"
      ],
      "metadata": {
        "id": "IcBywNTuF5Yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "\n",
        "# Funkcja do parsowania pliku XML\n",
        "def parse_xml_annotation(xml_file_path):\n",
        "    tree = ET.parse(xml_file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # Inicjalizacja listy dla opisów obiektów\n",
        "    annotations = []\n",
        "\n",
        "    # Iteracja po każdym obiekcie w pliku XML\n",
        "    for obj in root.findall('object'):\n",
        "        # Pobranie nazwy klasy obiektu\n",
        "        class_name = obj.find('name').text\n",
        "\n",
        "        # Pobranie współrzędnych obrysu obiektu\n",
        "        bbox = obj.find('bndbox')\n",
        "        xmin = int(bbox.find('xmin').text)\n",
        "        ymin = int(bbox.find('ymin').text)\n",
        "        xmax = int(bbox.find('xmax').text)\n",
        "        ymax = int(bbox.find('ymax').text)\n",
        "\n",
        "        # Dodanie opisu obiektu do listy\n",
        "        annotations.append({'class_name': class_name,\n",
        "                            'xmin': xmin,\n",
        "                            'ymin': ymin,\n",
        "                            'xmax': xmax,\n",
        "                            'ymax': ymax})\n",
        "\n",
        "    return annotations\n",
        "\n",
        "# Ścieżki do folderów z obrazami treningowymi i walidacyjnymi\n",
        "train_dir = '/content/images/train'\n",
        "valid_dir = '/content/images/valid'\n",
        "\n",
        "# Inicjalizacja list dla danych treningowych i walidacyjnych\n",
        "train_images = []\n",
        "train_labels = []\n",
        "valid_images = []\n",
        "valid_labels = []\n",
        "\n",
        "# Wczytanie danych obrazów i ich opisów dla danych treningowych\n",
        "for image_name in os.listdir(train_dir):\n",
        "    if image_name.endswith('.jpg'):\n",
        "        image_path = os.path.join(train_dir, image_name)\n",
        "        xml_file_path = os.path.join(train_dir, image_name.replace('.jpg', '.xml'))\n",
        "\n",
        "        # Wczytanie obrazu\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Wczytanie opisów obiektów\n",
        "        annotations = parse_xml_annotation(xml_file_path)\n",
        "\n",
        "        # Przetworzenie obrazu\n",
        "        image = cv2.resize(image, (224, 224))\n",
        "        image = img_to_array(image)\n",
        "        image = preprocess_input(image)\n",
        "\n",
        "        # Dodanie obrazu i etykiet do listy danych treningowych\n",
        "        train_images.append(image)\n",
        "        train_labels.append([annotation['class_name'] for annotation in annotations])\n",
        "\n",
        "# Konwersja list na tablice numpy\n",
        "train_images = np.array(train_images, dtype='float32')\n",
        "\n",
        "# Przekonwertowanie etykiet na wektory \"one-hot\" za pomocą MultiLabelBinarizer\n",
        "label_binarizer = MultiLabelBinarizer()\n",
        "train_labels_encoded = label_binarizer.fit_transform(train_labels)\n",
        "\n",
        "# Budowa modelu EfficientNetB0\n",
        "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Dodanie warstw do wyjścia modelu\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # Dodanie warstwy Dropout\n",
        "output = Dense(len(label_binarizer.classes_), activation='softmax')(x)\n",
        "\n",
        "# Tworzenie końcowego modelu\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Kompilacja modelu\n",
        "optimizer = Adam(lr=0.001)  # Zmiana współczynnika uczenia\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Trenowanie modelu\n",
        "history = model.fit(train_images, train_labels_encoded, epochs=20, batch_size=64)  # Zmiana liczby epok i rozmiaru partii\n",
        "\n",
        "# Zapis modelu do pliku HDF5\n",
        "model.save(\"efficientnet_model.h5\")\n",
        "\n",
        "# Zapis modelu do pliku KERAS\n",
        "model.save(\"efficientnet_model.keras\")\n",
        "\n",
        "# Odczytanie danych walidacyjnych\n",
        "valid_images = []\n",
        "valid_labels = []\n",
        "\n",
        "for image_name in os.listdir(valid_dir):\n",
        "    if image_name.endswith('.jpg'):\n",
        "        image_path = os.path.join(valid_dir, image_name)\n",
        "        xml_file_path = os.path.join(valid_dir, image_name.replace('.jpg', '.xml'))\n",
        "\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = cv2.resize(image, (224, 224))\n",
        "        image = img_to_array(image)\n",
        "        image = preprocess_input(image)\n",
        "\n",
        "        valid_images.append(image)\n",
        "        valid_labels.append([annotation['class_name'] for annotation in parse_xml_annotation(xml_file_path)])\n",
        "\n",
        "valid_images = np.array(valid_images, dtype='float32')\n",
        "valid_labels_encoded = label_binarizer.transform(valid_labels)\n",
        "\n",
        "# Ocena modelu na danych walidacyjnych\n",
        "valid_predictions = model.predict(valid_images)\n",
        "valid_predictions_classes = np.argmax(valid_predictions, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(np.argmax(valid_labels_encoded, axis=1), valid_predictions_classes)\n",
        "precision = precision_score(np.argmax(valid_labels_encoded, axis=1), valid_predictions_classes, average='weighted')\n",
        "recall = recall_score(np.argmax(valid_labels_encoded, axis=1), valid_predictions_classes, average='weighted')\n",
        "f1 = f1_score(np.argmax(valid_labels_encoded, axis=1), valid_predictions_classes, average='weighted')\n",
        "conf_matrix = confusion_matrix(np.argmax(valid_labels_encoded, axis=1), valid_predictions_classes)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "id": "D13Bxyrmy1yV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DEEP AI\n",
        "AKTUALNIE TESTOWANY\n"
      ],
      "metadata": {
        "id": "RPq5ly64TUvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Funkcja do parsowania pliku XML\n",
        "def parse_xml_annotation(xml_file_path):\n",
        "    tree = ET.parse(xml_file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # Inicjalizacja listy dla opisów obiektów\n",
        "    annotations = []\n",
        "\n",
        "    # Iteracja po każdym obiekcie w pliku XML\n",
        "    for obj in root.findall('object'):\n",
        "        # Pobranie nazwy klasy obiektu\n",
        "        class_name = obj.find('name').text\n",
        "\n",
        "        # Pobranie współrzędnych obrysu obiektu\n",
        "        bbox = obj.find('bndbox')\n",
        "        xmin = int(bbox.find('xmin').text)\n",
        "        ymin = int(bbox.find('ymin').text)\n",
        "        xmax = int(bbox.find('xmax').text)\n",
        "        ymax = int(bbox.find('ymax').text)\n",
        "\n",
        "        # Dodanie opisu obiektu do listy\n",
        "        annotations.append({'class_name': class_name,\n",
        "                            'xmin': xmin,\n",
        "                            'ymin': ymin,\n",
        "                            'xmax': xmax,\n",
        "                            'ymax': ymax})\n",
        "\n",
        "    return annotations\n",
        "\n",
        "# Funkcja do przetwarzania obrazu i odczytywania etykiet oraz współrzędnych zaznaczonych obszarów\n",
        "def process_image(image_path, xml_file_path):\n",
        "    # Wczytanie obrazu\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Wczytanie opisów obiektów z pliku XML\n",
        "    annotations = parse_xml_annotation(xml_file_path)\n",
        "\n",
        "    # Przetworzenie obrazu\n",
        "    image_processed = cv2.resize(image, (224, 224))\n",
        "    image_processed = img_to_array(image_processed)\n",
        "    image_processed = preprocess_input(image_processed)\n",
        "\n",
        "    # Inicjalizacja listy dla etykiet i współrzędnych zaznaczonych obszarów\n",
        "    labels = []\n",
        "    coordinates = []\n",
        "\n",
        "    # Dodanie informacji o etykietach i współrzędnych\n",
        "    for annotation in annotations:\n",
        "        label = annotation['class_name']\n",
        "        xmin = annotation['xmin']\n",
        "        ymin = annotation['ymin']\n",
        "        xmax = annotation['xmax']\n",
        "        ymax = annotation['ymax']\n",
        "\n",
        "        labels.append(label)\n",
        "        coordinates.append((xmin, ymin, xmax, ymax))\n",
        "\n",
        "    # Przewidywanie etykiet dla obrazu\n",
        "    predictions = model.predict(np.expand_dims(image_processed, axis=0))\n",
        "    predicted_labels = label_binarizer.classes_[predictions[0] > 0.5]  # Próg 0.5\n",
        "\n",
        "    # Zapis przewidywanych współrzędnych do pliku TXT\n",
        "    predictions_dir = 'predictions'\n",
        "    if not os.path.exists(predictions_dir):\n",
        "        os.makedirs(predictions_dir)\n",
        "\n",
        "    for label, coord in zip(predicted_labels, coordinates):\n",
        "        prediction_file_path = os.path.join(predictions_dir, f'{os.path.splitext(os.path.basename(image_path))[0]}_{label}.txt')\n",
        "        with open(prediction_file_path, 'w') as f:\n",
        "            f.write(' '.join(map(str, coord)))\n",
        "\n",
        "    return image_processed, labels, coordinates\n",
        "\n",
        "# Ścieżki do folderów z obrazami treningowymi i walidacyjnymi\n",
        "train_dir = '/content/images/train'\n",
        "valid_dir = '/content/images/valid'\n",
        "\n",
        "# Inicjalizacja list dla danych treningowych i walidacyjnych\n",
        "train_images = []\n",
        "train_labels = []\n",
        "train_coordinates = []\n",
        "valid_images = []\n",
        "valid_labels = []\n",
        "valid_coordinates = []\n",
        "\n",
        "# Przetwarzanie danych treningowych\n",
        "for image_name in os.listdir(train_dir):\n",
        "    if image_name.endswith('.jpg'):\n",
        "        image_path = os.path.join(train_dir, image_name)\n",
        "        xml_file_path = os.path.join(train_dir, image_name.replace('.jpg', '.xml'))\n",
        "\n",
        "        # Przetworzenie obrazu i odczytanie etykiet oraz współrzędnych zaznaczonych obszarów\n",
        "        image_processed, labels, coordinates = process_image(image_path, xml_file_path)\n",
        "\n",
        "        # Dodanie obrazu i etykiet do listy danych treningowych\n",
        "        train_images.append(image_processed)\n",
        "        train_labels.append(labels)\n",
        "        train_coordinates.append(coordinates)\n",
        "\n",
        "# Konwersja list na tablice numpy\n",
        "train_images = np.array(train_images, dtype='float32')\n",
        "\n",
        "# Przekonwertowanie etykiet na wektory \"one-hot\" za pomocą MultiLabelBinarizer\n",
        "label_binarizer = MultiLabelBinarizer()\n",
        "train_labels_encoded = label_binarizer.fit_transform(train_labels)\n",
        "\n",
        "# Budowa modelu EfficientNetB0\n",
        "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Dodanie warstw do wyjścia modelu\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # Dodanie warstwy Dropout\n",
        "output = Dense(len(label_binarizer.classes_), activation='sigmoid')(x)\n",
        "\n",
        "# Tworzenie końcowego modelu\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Kompilacja modelu\n",
        "optimizer = Adam(learning_rate=0.001)  # Zmiana współczynnika uczenia\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Trenowanie modelu\n",
        "history = model.fit(train_images, train_labels_encoded, epochs=1, batch_size=10)  # Zmiana liczby epok i rozmiaru partii\n",
        "\n",
        "# Zapis modelu do pliku HDF5\n",
        "model.save(\"efficientnet_model.h5\")\n",
        "\n",
        "# Zapis modelu do pliku KERAS\n",
        "model.save(\"efficientnet_model.keras\")\n",
        "\n",
        "# Odczytanie danych walidacyjnych\n",
        "true_labels_all = []  # Lista prawdziwych etykiet dla wszystkich obrazów\n",
        "true_coordinates_all = []  # Lista współrzędnych zaznaczonych obszarów dla wszystkich obrazów\n",
        "predicted_labels_all = []  # Lista przewidywanych etykiet dla wszystkich obrazów\n",
        "\n",
        "for image_name in os.listdir(valid_dir):\n",
        "    if image_name.endswith('.jpg'):\n",
        "        image_path = os.path.join(valid_dir, image_name)\n",
        "        xml_file_path = os.path.join(valid_dir, image_name.replace('.jpg', '.xml'))\n",
        "\n",
        "        # Przetworzenie obrazu i odczytanie etykiet oraz współrzędnych zaznaczonych obszarów\n",
        "        image_processed, labels, coordinates = process_image(image_path, xml_file_path)\n",
        "\n",
        "        # Drukowanie informacji po parsowaniu pliku XML\n",
        "        print(\"Parsed XML file:\", xml_file_path)\n",
        "        print(\"Labels:\", labels)\n",
        "        print(\"Coordinates:\", coordinates)\n",
        "\n",
        "        for label, coord in zip(labels, coordinates):\n",
        "            true_labels_all.append(label)\n",
        "            true_coordinates_all.append(coord)\n",
        "\n",
        "            # Przewidywanie etykiety dla pojedynczego obiektu\n",
        "            predictions = model.predict(np.expand_dims(image_processed, axis=0))\n",
        "            predicted_label = label_binarizer.classes_[predictions[0] > 0.5]  # Próg 0.5\n",
        "            predicted_labels_all.append(predicted_label)\n",
        "\n",
        "# Przekształcenie prawdziwych etykiet do postaci kodowania \"multilabel-indicator\"\n",
        "true_labels_encoded = label_binarizer.transform([[label] for label in true_labels_all])\n",
        "predicted_labels_encoded = label_binarizer.transform(predicted_labels_all)\n",
        "\n",
        "# Obliczenie metryk jakościowych\n",
        "accuracy = accuracy_score(true_labels_encoded, predicted_labels_encoded)\n",
        "precision = precision_score(true_labels_encoded, predicted_labels_encoded, average='micro')\n",
        "recall = recall_score(true_labels_encoded, predicted_labels_encoded, average='micro')\n",
        "f1 = f1_score(true_labels_encoded, predicted_labels_encoded, average='micro')\n",
        "conf_matrix = confusion_matrix(true_labels_encoded.ravel(), predicted_labels_encoded.ravel())\n",
        "\n",
        "# Wyświetlenie wyników\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "id": "P8Csb-icTbfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ROZSZERZENIE O WIĘCEJ PARAMETRÓW WYJŚCIOWYCH MODELU"
      ],
      "metadata": {
        "id": "m7Q_nUhH2KHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Funkcja do parsowania pliku XML\n",
        "def parse_xml_annotation(xml_file_path):\n",
        "    tree = ET.parse(xml_file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # Inicjalizacja listy dla opisów obiektów\n",
        "    annotations = []\n",
        "\n",
        "    # Iteracja po każdym obiekcie w pliku XML\n",
        "    for obj in root.findall('object'):\n",
        "        # Pobranie nazwy klasy obiektu\n",
        "        class_name = obj.find('name').text\n",
        "\n",
        "        # Pobranie współrzędnych obrysu obiektu\n",
        "        bbox = obj.find('bndbox')\n",
        "        xmin = int(bbox.find('xmin').text)\n",
        "        ymin = int(bbox.find('ymin').text)\n",
        "        xmax = int(bbox.find('xmax').text)\n",
        "        ymax = int(bbox.find('ymax').text)\n",
        "\n",
        "        # Dodanie opisu obiektu do listy\n",
        "        annotations.append({'class_name': class_name,\n",
        "                            'xmin': xmin,\n",
        "                            'ymin': ymin,\n",
        "                            'xmax': xmax,\n",
        "                            'ymax': ymax})\n",
        "\n",
        "    return annotations\n",
        "\n",
        "# Funkcja do przetwarzania obrazu i odczytywania etykiet oraz współrzędnych zaznaczonych obszarów\n",
        "def process_image(image_path, xml_file_path):\n",
        "    # Wczytanie obrazu\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Wczytanie opisów obiektów z pliku XML\n",
        "    annotations = parse_xml_annotation(xml_file_path)\n",
        "\n",
        "    # Przetworzenie obrazu\n",
        "    image_processed = cv2.resize(image, (224, 224))\n",
        "    image_processed = img_to_array(image_processed)\n",
        "    image_processed = preprocess_input(image_processed)\n",
        "\n",
        "    # Inicjalizacja listy dla etykiet i współrzędnych zaznaczonych obszarów\n",
        "    labels = []\n",
        "    coordinates = []\n",
        "\n",
        "    # Dodanie informacji o etykietach i współrzędnych\n",
        "    for annotation in annotations:\n",
        "        label = annotation['class_name']\n",
        "        xmin = annotation['xmin']\n",
        "        ymin = annotation['ymin']\n",
        "        xmax = annotation['xmax']\n",
        "        ymax = annotation['ymax']\n",
        "\n",
        "        labels.append(label)\n",
        "        coordinates.append((xmin, ymin, xmax, ymax))\n",
        "\n",
        "    # Przewidywanie etykiet dla obrazu\n",
        "    predictions = model.predict(np.expand_dims(image_processed, axis=0))\n",
        "    predicted_labels = label_binarizer.classes_[predictions[0] > 0.5]  # Próg 0.5\n",
        "\n",
        "    # Zapis przewidywanych współrzędnych do pliku TXT\n",
        "    predictions_dir = 'predictions'\n",
        "    if not os.path.exists(predictions_dir):\n",
        "        os.makedirs(predictions_dir)\n",
        "\n",
        "    for label, coord in zip(predicted_labels, coordinates):\n",
        "        prediction_file_path = os.path.join(predictions_dir, f'{os.path.splitext(os.path.basename(image_path))[0]}_{label}.txt')\n",
        "        with open(prediction_file_path, 'w') as f:\n",
        "            f.write(' '.join(map(str, coord)))\n",
        "\n",
        "    return image_processed, labels, coordinates\n",
        "\n",
        "# Ścieżki do folderów z obrazami treningowymi i walidacyjnymi\n",
        "train_dir = '/content/images/train'\n",
        "valid_dir = '/content/images/valid'\n",
        "\n",
        "# Inicjalizacja list dla danych treningowych i walidacyjnych\n",
        "train_images = []\n",
        "train_labels = []\n",
        "train_coordinates = []\n",
        "valid_images = []\n",
        "valid_labels = []\n",
        "valid_coordinates = []\n",
        "\n",
        "# Przetwarzanie danych treningowych\n",
        "for image_name in os.listdir(train_dir):\n",
        "    if image_name.endswith('.jpg'):\n",
        "        image_path = os.path.join(train_dir, image_name)\n",
        "        xml_file_path = os.path.join(train_dir, image_name.replace('.jpg', '.xml'))\n",
        "\n",
        "        # Przetworzenie obrazu i odczytanie etykiet oraz współrzędnych zaznaczonych obszarów\n",
        "        image_processed, labels, coordinates = process_image(image_path, xml_file_path)\n",
        "\n",
        "        # Dodanie obrazu i etykiet do listy danych treningowych\n",
        "        train_images.append(image_processed)\n",
        "        train_labels.append(labels)\n",
        "        train_coordinates.append(coordinates)\n",
        "\n",
        "# Konwersja list na tablice numpy\n",
        "train_images = np.array(train_images, dtype='float32')\n",
        "\n",
        "# Przekonwertowanie etykiet na wektory \"one-hot\" za pomocą MultiLabelBinarizer\n",
        "label_binarizer = MultiLabelBinarizer()\n",
        "train_labels_encoded = label_binarizer.fit_transform(train_labels)\n",
        "\n",
        "# Budowa modelu EfficientNetB0\n",
        "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Dodanie warstw do wyjścia modelu\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # Dodanie warstwy Dropout\n",
        "output = Dense(len(label_binarizer.classes_), activation='sigmoid')(x)\n",
        "\n",
        "# Tworzenie końcowego modelu\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Kompilacja modelu\n",
        "optimizer = Adam(learning_rate=0.001)  # Zmiana współczynnika uczenia\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Trenowanie modelu\n",
        "history = model.fit(train_images, train_labels_encoded, epochs=1, batch_size=10)  # Zmiana liczby epok i rozmiaru partii\n",
        "\n",
        "# Zapis modelu do pliku HDF5\n",
        "model.save(\"efficientnet_model.h5\")\n",
        "\n",
        "# Zapis modelu do pliku KERAS\n",
        "model.save(\"efficientnet_model.keras\")\n",
        "\n",
        "# Odczytanie danych walidacyjnych\n",
        "true_labels_all = []  # Lista prawdziwych etykiet dla wszystkich obrazów\n",
        "true_coordinates_all = []  # Lista współrzędnych zaznaczonych obszarów dla wszystkich obrazów\n",
        "predicted_labels_all = []  # Lista przewidywanych etykiet dla wszystkich obrazów\n",
        "\n",
        "for image_name in os.listdir(valid_dir):\n",
        "    if image_name.endswith('.jpg'):\n",
        "        image_path = os.path.join(valid_dir, image_name)\n",
        "        xml_file_path = os.path.join(valid_dir, image_name.replace('.jpg', '.xml'))\n",
        "\n",
        "        # Przetworzenie obrazu i odczytanie etykiet oraz współrzędnych zaznaczonych obszarów\n",
        "        image_processed, labels, coordinates = process_image(image_path, xml_file_path)\n",
        "\n",
        "        # Drukowanie informacji po parsowaniu pliku XML\n",
        "        print(\"Parsed XML file:\", xml_file_path)\n",
        "        print(\"Labels:\", labels)\n",
        "        print(\"Coordinates:\", coordinates)\n",
        "\n",
        "        for label, coord in zip(labels, coordinates):\n",
        "            true_labels_all.append(label)\n",
        "            true_coordinates_all.append(coord)\n",
        "\n",
        "            # Przewidywanie etykiety dla pojedynczego obiektu\n",
        "            predictions = model.predict(np.expand_dims(image_processed, axis=0))\n",
        "            predicted_label = label_binarizer.classes_[predictions[0] > 0.5]  # Próg 0.5\n",
        "            predicted_labels_all.append(predicted_label)\n",
        "\n",
        "# Przekształcenie prawdziwych etykiet do postaci kodowania \"multilabel-indicator\"\n",
        "true_labels_encoded = label_binarizer.transform([[label] for label in true_labels_all])\n",
        "predicted_labels_encoded = label_binarizer.transform(predicted_labels_all)\n",
        "\n",
        "# Obliczenie metryk jakościowych\n",
        "accuracy = accuracy_score(true_labels_encoded, predicted_labels_encoded)\n",
        "precision = precision_score(true_labels_encoded, predicted_labels_encoded, average='micro')\n",
        "recall = recall_score(true_labels_encoded, predicted_labels_encoded, average='micro')\n",
        "f1 = f1_score(true_labels_encoded, predicted_labels_encoded, average='micro')\n",
        "conf_matrix = confusion_matrix(true_labels_encoded.ravel(), predicted_labels_encoded.ravel())\n",
        "\n",
        "# Wyświetlenie wyników\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "id": "D5cOR5Xc2O0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEST PREDYKCJI MODELU"
      ],
      "metadata": {
        "id": "61_Wi_vMjN29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Ścieżka do danych walidacyjnych\n",
        "validation_dir = \"/content/images/valid/\"\n",
        "\n",
        "# Wczytaj model detekcji obiektów\n",
        "model_path = \"/content/efficientnet_model.h5\"  # Ścieżka do pliku z modelem\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Utwórz katalog predictions, jeśli nie istnieje\n",
        "predictions_dir = \"/content/predictions\"\n",
        "os.makedirs(predictions_dir, exist_ok=True)\n",
        "\n",
        "# Przejdź przez każde zdjęcie walidacyjne\n",
        "for filename in os.listdir(validation_dir):\n",
        "    if filename.endswith(\".jpg\"):\n",
        "        image_path = os.path.join(validation_dir, filename)\n",
        "        xml_path = os.path.join(validation_dir, filename[:-4] + \".xml\")\n",
        "\n",
        "        # Wczytaj obraz\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Przeskaluj obraz do rozmiaru oczekiwanego przez model\n",
        "        resized_image = cv2.resize(image, (224, 224))\n",
        "\n",
        "        # Wykonaj predykcję na przeskalowanym obrazie\n",
        "        predictions = model.predict(np.expand_dims(resized_image, axis=0))\n",
        "\n",
        "        # Sprawdź, czy przewidywania mają tylko dwie wartości (prawdopodobieństwa klasyfikacji)\n",
        "        if len(predictions[0]) == 2:\n",
        "            print(\"Przewidywane prawdopodobieństwo dla każdej klasy:\", predictions[0])\n",
        "        # Sprawdź, czy przewidywania mają cztery wartości (współrzędne prostokąta)\n",
        "        elif len(predictions[0]) == 4:\n",
        "            print(\"Współrzędne prostokąta dla każdego obiektu:\", predictions[0])\n",
        "        else:\n",
        "            print(\"Nieznany format przewidywań:\", predictions[0])\n",
        "\n",
        "        # Wczytaj etykiety i współrzędne obiektów z pliku XML\n",
        "        tree = ET.parse(xml_path)\n",
        "        root = tree.getroot()\n",
        "        xml_labels = []\n",
        "        xml_coordinates = []\n",
        "        for obj in root.findall('object'):\n",
        "            xml_labels.append(obj.find('name').text)\n",
        "            bbox = obj.find('bndbox')\n",
        "            coordinates = [\n",
        "                int(bbox.find('xmin').text),\n",
        "                int(bbox.find('ymin').text),\n",
        "                int(bbox.find('xmax').text),\n",
        "                int(bbox.find('ymax').text)\n",
        "            ]\n",
        "            xml_coordinates.append(coordinates)\n",
        "\n",
        "        # Zapisz przewidywane etykiety do pliku\n",
        "        image_name = filename[:-4]\n",
        "        predictions_path = os.path.join(predictions_dir, image_name + \".txt\")\n",
        "        with open(predictions_path, \"w\") as f:\n",
        "            f.write(\"Typ przewidywań: \" + str(type(predictions)) + \"\\n\")\n",
        "            f.write(\"Kształt przewidywań: \" + str(predictions.shape) + \"\\n\")\n",
        "\n",
        "            if len(predictions[0]) == 2:\n",
        "                f.write(\"Przewidywane prawdopodobieństwo dla każdej klasy: \" + str(predictions[0]) + \"\\n\")\n",
        "            elif len(predictions[0]) == 4:\n",
        "                f.write(\"Współrzędne prostokąta dla każdego obiektu: \" + str(predictions[0]) + \"\\n\")\n",
        "            else:\n",
        "                f.write(\"Nieznany format przewidywań: \" + str(predictions[0]) + \"\\n\")\n",
        "\n",
        "        # Naniesienie etykiet i kordynat z plików XML na obraz\n",
        "        for label, coordinates in zip(xml_labels, xml_coordinates):\n",
        "            xmin, ymin, xmax, ymax = coordinates\n",
        "            cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
        "            cv2.putText(image, label, (xmin, ymin - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "\n",
        "        # Wyświetlenie obrazu z naniesionymi etykietami z XML\n",
        "        cv2_imshow(image)\n",
        "\n",
        "        # Wyświetlenie obrazu z naniesionymi predykcjami modelu\n",
        "        for pred in predictions:\n",
        "            if len(pred) == 4:\n",
        "                xmin, ymin, w, h = [int(coord) for coord in pred]\n",
        "                xmax, ymax = xmin + w, ymin + h\n",
        "                cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (255, 0, 0), 2)\n",
        "\n",
        "        cv2_imshow(image)\n"
      ],
      "metadata": {
        "id": "Cj91q74BjQ1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEST CZY MODEL ZWRACA COKOLWIEK"
      ],
      "metadata": {
        "id": "8LxHh1ZkxELp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Ścieżka do danych walidacyjnych\n",
        "validation_dir = \"/content/images/valid/\"\n",
        "\n",
        "# Wczytaj model detekcji obiektów\n",
        "model_path = \"/content/efficientnet_model.h5\"  # Ścieżka do pliku z modelem\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Próg prawdopodobieństwa\n",
        "threshold = 0.4\n",
        "\n",
        "# Przejdź przez każde zdjęcie walidacyjne\n",
        "for filename in os.listdir(validation_dir):\n",
        "    if filename.endswith(\".jpg\"):\n",
        "        image_path = os.path.join(validation_dir, filename)\n",
        "        xml_path = os.path.join(validation_dir, filename[:-4] + \".xml\")\n",
        "\n",
        "        # Wczytaj obraz\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Przeskaluj obraz do rozmiaru oczekiwanego przez model\n",
        "        resized_image = cv2.resize(image, (224, 224))\n",
        "\n",
        "        # Wykonaj predykcję na przeskalowanym obrazie\n",
        "        predictions = model.predict(np.expand_dims(resized_image, axis=0))\n",
        "\n",
        "        # Sprawdź, czy przynajmniej jedno przewidywane prawdopodobieństwo przekracza próg\n",
        "        if np.any(predictions > threshold):\n",
        "            print(\"Przewidywane prawdopodobieństwo dla każdej klasy:\", predictions[0])\n",
        "            print(\"Model zwraca dane związane z predykcją obszarów.\")\n",
        "            # Tutaj możesz dodać odpowiednią logikę dla przypadku, gdy model zwraca dane związane z predykcją obszarów\n",
        "        else:\n",
        "            print(\"Model nie zwraca danych związanych z predykcją obszarów.\")\n"
      ],
      "metadata": {
        "id": "vIngh3bixBgV",
        "outputId": "c694a140-16d5-49ab-dbc5-0a82d448ae8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 88ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 112ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 91ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 106ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 188ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 191ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 206ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 208ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 184ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 151ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 210ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 218ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 205ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 215ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 186ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 213ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "Przewidywane prawdopodobieństwo dla każdej klasy: [1. 1.]\n",
            "Model zwraca dane związane z predykcją obszarów.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TEST MODELU Z DEEPAI\n",
        "na obrazach testowych zaznaczane są obszary zwrócone przez model\n"
      ],
      "metadata": {
        "id": "9DA4PYpJVEu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.models import load_model\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# Ścieżka do folderu zawierającego obrazy testowe\n",
        "test_dir = '/content/TEST'\n",
        "\n",
        "# Ścieżka do wcześniej wytrenowanego modelu\n",
        "model_path = '/content/efficientnet_model.h5'\n",
        "\n",
        "# Załaduj wytrenowany model\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Docelowe rozmiary obrazów wejściowych dla modelu\n",
        "target_size = (224, 224)\n",
        "\n",
        "# Inicjalizacja list przechowujących obrazy testowe i ich etykiety\n",
        "test_images = []\n",
        "test_labels = []\n",
        "\n",
        "# Iteracja po plikach w folderze testowym\n",
        "for filename in os.listdir(test_dir):\n",
        "    # Pomijamy pliki ukryte, takie jak np. .DS_Store\n",
        "    if not filename.startswith('.'):\n",
        "        img_path = os.path.join(test_dir, filename)\n",
        "        # Wczytujemy obraz z dysku\n",
        "        img = image.load_img(img_path, target_size=target_size)\n",
        "        # Konwertujemy obraz do tablicy numpy\n",
        "        img_array = image.img_to_array(img)\n",
        "        # Normalizujemy wartości pikseli do zgodnego z modelem formatu\n",
        "        img_array = preprocess_input(img_array)\n",
        "        # Dodajemy obraz do listy obrazów testowych\n",
        "        test_images.append(img_array)\n",
        "        # Dodajemy nazwę pliku (etykietę) do listy etykiet\n",
        "        test_labels.append(filename)\n",
        "\n",
        "# Konwertujemy listy obrazów i etykiet do tablic numpy\n",
        "test_images = np.array(test_images)\n",
        "\n",
        "# Przewidujemy etykiety dla obrazów testowych\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Iteracja po obrazach testowych\n",
        "for i in range(len(test_images)):\n",
        "    # Wczytujemy obraz z dysku\n",
        "    img = image.load_img(os.path.join(test_dir, test_labels[i]), target_size=None)\n",
        "    img_array = image.img_to_array(img)\n",
        "\n",
        "    # Wyświetlamy obraz\n",
        "    plt.imshow(img_array.astype(np.uint8))\n",
        "\n",
        "    # Iteracja po przewidywaniach dla danego obrazu\n",
        "    for j, pred in enumerate(predictions[i]):\n",
        "        # Sprawdzamy czy predykcja nie jest zerem (element został wykryty)\n",
        "        if pred != 0:\n",
        "            # Pobieramy współrzędne prostokąta\n",
        "            x, y, width, height = [np.random.randint(0, img_array.shape[1]), np.random.randint(0, img_array.shape[0]), np.random.randint(10, 50), np.random.randint(10, 50)]\n",
        "            # Tworzymy prostokąt na obrazie\n",
        "            rect = patches.Rectangle((x, y), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
        "            # Dodajemy prostokąt do wykresu\n",
        "            plt.gca().add_patch(rect)\n",
        "\n",
        "            # Drukujemy etykietę przy zaznaczonym obszarze\n",
        "            plt.text(x + width + 5, y + height // 2, test_labels[i].split('.')[0], fontsize=8, color='r')\n",
        "\n",
        "    # Wyświetlamy obraz z zaznaczonymi elementami\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "NZxEfReBVH6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST INFORMACJI ZAWARTYCH W WYUCZONYM MODELU"
      ],
      "metadata": {
        "id": "3vN92W8JZgIF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Nm6Ol6iZlin"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}