{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0O4AjaRLjJq+B/HueQDiw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jakless/mgr2024/blob/main/Model_20240514.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ROZPAKOWYWANIE**"
      ],
      "metadata": {
        "id": "DXoSztcS8H54"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Q4OwPHVN6GTU"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "def unzip_file(zip_file_path, extract_to_path):\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to_path)\n",
        "\n",
        "# Przykładowe użycie funkcji:\n",
        "zip_file_path = '/content/yolo.zip'\n",
        "extract_to_path = '/content/yolo'\n",
        "unzip_file(zip_file_path, extract_to_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **USUWANIE ELEMENTÓW FOLDERU**"
      ],
      "metadata": {
        "id": "kSQpneKq8NCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Ścieżka do folderu, który chcemy oczyścić\n",
        "folder_path = '/content/yolo'\n",
        "\n",
        "# Usunięcie wszystkich plików z folderu\n",
        "for filename in os.listdir(folder_path):\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "    try:\n",
        "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "            os.unlink(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "            os.rmdir(file_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to delete {file_path}. Reason: {e}\")\n"
      ],
      "metadata": {
        "id": "_KztYVHD8RFx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PAKOWANIE W ZIPA**"
      ],
      "metadata": {
        "id": "7JmffbBAtseY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Ścieżka do folderu do spakowania\n",
        "folder_to_zip = '/content/yolo'\n",
        "\n",
        "# Ścieżka, pod którą chcesz zapisać plik zip\n",
        "output_zip_file = '/content/yolo'\n",
        "\n",
        "# Spakowanie folderu\n",
        "shutil.make_archive(output_zip_file, 'zip', folder_to_zip)\n",
        "\n",
        "# Sprawdzenie, czy plik zip został utworzony\n",
        "if os.path.exists(output_zip_file):\n",
        "    print(\"Plik zip został utworzony pomyślnie.\")\n",
        "else:\n",
        "    print(\"Wystąpił problem podczas tworzenia pliku zip.\")\n"
      ],
      "metadata": {
        "id": "RpR-ljjytzUq",
        "outputId": "fd20eb06-2843-4fe4-dc45-c4062085770d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plik zip został utworzony pomyślnie.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**EFFICIENT_NET**"
      ],
      "metadata": {
        "id": "PN4aixWKK2hf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. WCZYTANIE MODELU**"
      ],
      "metadata": {
        "id": "IUqt-egTqcsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "# Wczytanie wytrenowanego modelu\n",
        "model = load_model(\"efficientnet_model.h5\")\n",
        "\n",
        "# Funkcja do przetwarzania obrazu\n",
        "def preprocess_image(image_path):\n",
        "    # Wczytanie obrazu\n",
        "    image = load_img(image_path, target_size=(224, 224))\n",
        "    image = img_to_array(image)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    # Przetworzenie obrazu do formatu akceptowanego przez model EfficientNet\n",
        "    image = preprocess_input(image)\n",
        "\n",
        "    return image\n",
        "\n",
        "# Wczytanie obrazu do przetwarzania\n",
        "image_path = '/content/images/train/zdjecie1.jpg'  # Zmień na ścieżkę do swojego obrazu\n",
        "image = preprocess_image(image_path)\n",
        "\n",
        "# Przewidywanie etykiet dla obrazu\n",
        "predictions = model.predict(image)\n",
        "\n",
        "# Określenie progu dla prawdopodobieństwa\n",
        "threshold = 0.5\n",
        "\n",
        "# Wyświetlanie wyników przewidywań\n",
        "print(\"Wyniki przewidywań:\")\n",
        "print(predictions)\n",
        "\n",
        "# Wczytanie obrazu do wyświetlenia\n",
        "image_display = cv2.imread(image_path)\n",
        "image_display = cv2.cvtColor(image_display, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Znalezienie obszaru z najwyższym prawdopodobieństwem dla klasy \"GREY\"\n",
        "grey_class_index = label_encoder.index('GREY')\n",
        "grey_class_activation = model.layers[-2].output[:, grey_class_index]\n",
        "\n",
        "# Znalezienie współrzędnych maksymalnej aktywacji\n",
        "activation_map = tf.squeeze(grey_class_activation)\n",
        "activation_map = tf.nn.max_pool2d(activation_map[None,None,...], 10, 1, padding='SAME')\n",
        "\n",
        "# Utworzenie funkcji TensorFlow\n",
        "@tf.function\n",
        "def get_activation_map_value():\n",
        "    return activation_map\n",
        "\n",
        "# Pobranie wartości tensora w kontekście TensorFlow\n",
        "activation_map_value = get_activation_map_value()\n",
        "\n",
        "# Znalezienie współrzędnych maksymalnej aktywacji\n",
        "ymax, xmax = np.unravel_index(np.argmax(np.reshape(activation_map_value, (-1,))), activation_map_value.shape[1:])\n",
        "xmin, ymin = xmax - 224, ymax - 224  # Oblicz współrzędne rogu górnego lewego\n",
        "\n",
        "# Wydrukuj lokalizację wykrytego elementu \"GREY\"\n",
        "print(f\"Współrzędne dla GREY: (xmin={xmin}, ymin={ymin}), (xmax={xmax}, ymax={ymax})\")\n",
        "\n",
        "# Zaznaczenie wykrytego obiektu za pomocą prostokąta\n",
        "cv2.rectangle(image_display, (xmin, ymin), (xmax, ymax), (255, 0, 0), 2)\n",
        "\n",
        "# Wyświetlenie obrazu\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(image_display)\n"
      ],
      "metadata": {
        "id": "e6fP01rHqgRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. KOD WYSZUKUJĄCY WSZYSTKIE ETYKIETY I ELEMENTY**"
      ],
      "metadata": {
        "id": "ggDXpRH4yudx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Accuracy: 0.38 Precision: 1.0 Recall: 0.38 F1 Score: 0.55 Confusion Matrix:[[19 31][ 0  0]]"
      ],
      "metadata": {
        "id": "IcBywNTuF5Yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "\n",
        "# Funkcja do parsowania pliku XML\n",
        "def parse_xml_annotation(xml_file_path):\n",
        "    tree = ET.parse(xml_file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # Inicjalizacja listy dla opisów obiektów\n",
        "    annotations = []\n",
        "\n",
        "    # Iteracja po każdym obiekcie w pliku XML\n",
        "    for obj in root.findall('object'):\n",
        "        # Pobranie nazwy klasy obiektu\n",
        "        class_name = obj.find('name').text\n",
        "\n",
        "        # Pobranie współrzędnych obrysu obiektu\n",
        "        bbox = obj.find('bndbox')\n",
        "        xmin = int(bbox.find('xmin').text)\n",
        "        ymin = int(bbox.find('ymin').text)\n",
        "        xmax = int(bbox.find('xmax').text)\n",
        "        ymax = int(bbox.find('ymax').text)\n",
        "\n",
        "        # Dodanie opisu obiektu do listy\n",
        "        annotations.append({'class_name': class_name,\n",
        "                            'xmin': xmin,\n",
        "                            'ymin': ymin,\n",
        "                            'xmax': xmax,\n",
        "                            'ymax': ymax})\n",
        "\n",
        "    return annotations\n",
        "\n",
        "# Ścieżki do folderów z obrazami treningowymi i walidacyjnymi\n",
        "train_dir = '/content/images/train'\n",
        "valid_dir = '/content/images/valid'\n",
        "\n",
        "# Inicjalizacja list dla danych treningowych i walidacyjnych\n",
        "train_images = []\n",
        "train_labels = []\n",
        "valid_images = []\n",
        "valid_labels = []\n",
        "\n",
        "# Wczytanie danych obrazów i ich opisów dla danych treningowych\n",
        "for image_name in os.listdir(train_dir):\n",
        "    if image_name.endswith('.jpg'):\n",
        "        image_path = os.path.join(train_dir, image_name)\n",
        "        xml_file_path = os.path.join(train_dir, image_name.replace('.jpg', '.xml'))\n",
        "\n",
        "        # Wczytanie obrazu\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Wczytanie opisów obiektów\n",
        "        annotations = parse_xml_annotation(xml_file_path)\n",
        "\n",
        "        # Przetworzenie obrazu\n",
        "        image = cv2.resize(image, (224, 224))\n",
        "        image = img_to_array(image)\n",
        "        image = preprocess_input(image)\n",
        "\n",
        "        # Dodanie obrazu i etykiet do listy danych treningowych\n",
        "        train_images.append(image)\n",
        "        train_labels.append([annotation['class_name'] for annotation in annotations])\n",
        "\n",
        "# Konwersja list na tablice numpy\n",
        "train_images = np.array(train_images, dtype='float32')\n",
        "\n",
        "# Przekonwertowanie etykiet na wektory \"one-hot\" za pomocą MultiLabelBinarizer\n",
        "label_binarizer = MultiLabelBinarizer()\n",
        "train_labels_encoded = label_binarizer.fit_transform(train_labels)\n",
        "\n",
        "# Budowa modelu EfficientNetB0\n",
        "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Dodanie warstw do wyjścia modelu\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # Dodanie warstwy Dropout\n",
        "output = Dense(len(label_binarizer.classes_), activation='softmax')(x)\n",
        "\n",
        "# Tworzenie końcowego modelu\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Kompilacja modelu\n",
        "optimizer = Adam(lr=0.001)  # Zmiana współczynnika uczenia\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Trenowanie modelu\n",
        "history = model.fit(train_images, train_labels_encoded, epochs=20, batch_size=64)  # Zmiana liczby epok i rozmiaru partii\n",
        "\n",
        "# Zapis modelu do pliku HDF5\n",
        "model.save(\"efficientnet_model.h5\")\n",
        "\n",
        "# Zapis modelu do pliku KERAS\n",
        "model.save(\"efficientnet_model.keras\")\n",
        "\n",
        "# Odczytanie danych walidacyjnych\n",
        "valid_images = []\n",
        "valid_labels = []\n",
        "\n",
        "for image_name in os.listdir(valid_dir):\n",
        "    if image_name.endswith('.jpg'):\n",
        "        image_path = os.path.join(valid_dir, image_name)\n",
        "        xml_file_path = os.path.join(valid_dir, image_name.replace('.jpg', '.xml'))\n",
        "\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = cv2.resize(image, (224, 224))\n",
        "        image = img_to_array(image)\n",
        "        image = preprocess_input(image)\n",
        "\n",
        "        valid_images.append(image)\n",
        "        valid_labels.append([annotation['class_name'] for annotation in parse_xml_annotation(xml_file_path)])\n",
        "\n",
        "valid_images = np.array(valid_images, dtype='float32')\n",
        "valid_labels_encoded = label_binarizer.transform(valid_labels)\n",
        "\n",
        "# Ocena modelu na danych walidacyjnych\n",
        "valid_predictions = model.predict(valid_images)\n",
        "valid_predictions_classes = np.argmax(valid_predictions, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(np.argmax(valid_labels_encoded, axis=1), valid_predictions_classes)\n",
        "precision = precision_score(np.argmax(valid_labels_encoded, axis=1), valid_predictions_classes, average='weighted')\n",
        "recall = recall_score(np.argmax(valid_labels_encoded, axis=1), valid_predictions_classes, average='weighted')\n",
        "f1 = f1_score(np.argmax(valid_labels_encoded, axis=1), valid_predictions_classes, average='weighted')\n",
        "conf_matrix = confusion_matrix(np.argmax(valid_labels_encoded, axis=1), valid_predictions_classes)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "id": "D13Bxyrmy1yV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DEEP AI\n",
        "AKTUALNIE TESTOWANY\n"
      ],
      "metadata": {
        "id": "RPq5ly64TUvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Funkcja do parsowania pliku XML\n",
        "def parse_xml_annotation(xml_file_path):\n",
        "    tree = ET.parse(xml_file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # Inicjalizacja listy dla opisów obiektów\n",
        "    annotations = []\n",
        "\n",
        "    # Iteracja po każdym obiekcie w pliku XML\n",
        "    for obj in root.findall('object'):\n",
        "        # Pobranie nazwy klasy obiektu\n",
        "        class_name = obj.find('name').text\n",
        "\n",
        "        # Pobranie współrzędnych obrysu obiektu\n",
        "        bbox = obj.find('bndbox')\n",
        "        xmin = int(bbox.find('xmin').text)\n",
        "        ymin = int(bbox.find('ymin').text)\n",
        "        xmax = int(bbox.find('xmax').text)\n",
        "        ymax = int(bbox.find('ymax').text)\n",
        "\n",
        "        # Dodanie opisu obiektu do listy\n",
        "        annotations.append({'class_name': class_name,\n",
        "                            'xmin': xmin,\n",
        "                            'ymin': ymin,\n",
        "                            'xmax': xmax,\n",
        "                            'ymax': ymax})\n",
        "\n",
        "    return annotations\n",
        "\n",
        "# Funkcja do przetwarzania obrazu i odczytywania etykiet oraz współrzędnych zaznaczonych obszarów\n",
        "def process_image(image_path, xml_file_path):\n",
        "    # Wczytanie obrazu\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Wczytanie opisów obiektów z pliku XML\n",
        "    annotations = parse_xml_annotation(xml_file_path)\n",
        "\n",
        "    # Przetworzenie obrazu\n",
        "    image_processed = cv2.resize(image, (224, 224))\n",
        "    image_processed = img_to_array(image_processed)\n",
        "    image_processed = preprocess_input(image_processed)\n",
        "\n",
        "    # Inicjalizacja listy dla etykiet i współrzędnych zaznaczonych obszarów\n",
        "    labels = []\n",
        "    coordinates = []\n",
        "\n",
        "    # Dodanie informacji o etykietach i współrzędnych\n",
        "    for annotation in annotations:\n",
        "        label = annotation['class_name']\n",
        "        xmin = annotation['xmin']\n",
        "        ymin = annotation['ymin']\n",
        "        xmax = annotation['xmax']\n",
        "        ymax = annotation['ymax']\n",
        "\n",
        "        labels.append(label)\n",
        "        coordinates.append((xmin, ymin, xmax, ymax))\n",
        "\n",
        "    # Przewidywanie etykiet i współrzędnych dla obrazu\n",
        "    predictions = model.predict(np.expand_dims(image_processed, axis=0))\n",
        "    predicted_labels = label_binarizer.classes_[predictions[0] > 0.5]  # Próg 0.5\n",
        "\n",
        "    # Tworzenie katalogu \"predictions\", jeśli nie istnieje\n",
        "    predictions_dir = 'predictions'\n",
        "    if not os.path.exists(predictions_dir):\n",
        "        os.makedirs(predictions_dir)\n",
        "\n",
        "    # Zapis przewidywanych współrzędnych do pliku tekstowego\n",
        "    for label, coord in zip(predicted_labels, coordinates):\n",
        "        prediction_file_path = os.path.join(predictions_dir, f'{os.path.splitext(os.path.basename(image_path))[0]}_{label}.txt')\n",
        "        with open(prediction_file_path, 'w') as f:\n",
        "            f.write(' '.join(map(str, coord)))\n",
        "\n",
        "    return image_processed, labels, coordinates\n",
        "\n",
        "# Ścieżki do folderów z obrazami treningowymi i walidacyjnymi\n",
        "train_dir = '/content/images/train'\n",
        "valid_dir = '/content/images/valid'\n",
        "\n",
        "# Inicjalizacja list dla danych treningowych i walidacyjnych\n",
        "train_images = []\n",
        "train_labels = []\n",
        "train_coordinates = []\n",
        "valid_images = []\n",
        "valid_labels = []\n",
        "valid_coordinates = []\n",
        "\n",
        "# Przetwarzanie danych treningowych\n",
        "for image_name in os.listdir(train_dir):\n",
        "    if image_name.endswith('.jpg'):\n",
        "        image_path = os.path.join(train_dir, image_name)\n",
        "        xml_file_path = os.path.join(train_dir, image_name.replace('.jpg', '.xml'))\n",
        "\n",
        "        # Przetworzenie obrazu i odczytanie etykiet oraz współrzędnych zaznaczonych obszarów\n",
        "        image_processed, labels, coordinates = process_image(image_path, xml_file_path)\n",
        "\n",
        "        # Dodanie obrazu i etykiet do listy danych treningowych\n",
        "        train_images.append(image_processed)\n",
        "        train_labels.append(labels)\n",
        "        train_coordinates.append(coordinates)\n",
        "\n",
        "# Konwersja list na tablice numpy\n",
        "train_images = np.array(train_images, dtype='float32')\n",
        "\n",
        "# Przekonwertowanie etykiet na wektory \"one-hot\" za pomocą MultiLabelBinarizer\n",
        "label_binarizer = MultiLabelBinarizer()\n",
        "train_labels_encoded = label_binarizer.fit_transform(train_labels)\n",
        "\n",
        "# Budowa modelu EfficientNetB0\n",
        "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Dodanie warstw do wyjścia modelu\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # Dodanie warstwy Dropout\n",
        "output_classes = Dense(len(label_binarizer.classes_), activation='sigmoid')(x)\n",
        "\n",
        "# Tworzenie końcowego modelu\n",
        "model = Model(inputs=base_model.input, outputs=output_classes)\n",
        "\n",
        "# Kompilacja modelu\n",
        "optimizer = Adam(learning_rate=0.001)  # Zmiana współczynnika uczenia\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Trenowanie modelu\n",
        "history = model.fit(train_images, train_labels_encoded, epochs=1, batch_size=10)  # Zmiana liczby epok i rozmiaru partii\n",
        "\n",
        "# Zapis modelu do pliku HDF5\n",
        "model.save(\"efficientnet_model.h5\")\n",
        "\n",
        "# Zapis modelu do pliku KERAS\n",
        "model.save(\"efficientnet_model.keras\")\n",
        "\n",
        "\n",
        "\n",
        "# Odczytanie danych walidacyjnych\n",
        "true_labels_all = []  # Lista prawdziwych etykiet dla wszystkich obrazów\n",
        "true_coordinates_all = []  # Lista współrzędnych zaznaczonych obszarów dla wszystkich obrazów\n",
        "predicted_labels_all = []  # Lista przewidywanych etykiet dla wszystkich obrazów\n",
        "predicted_coordinates_all = []  # Lista przewidywanych współrzędnych dla wszystkich obrazów\n",
        "\n",
        "for image_name in os.listdir(valid_dir):\n",
        "    if image_name.endswith('.jpg'):\n",
        "        image_path = os.path.join(valid_dir, image_name)\n",
        "        xml_file_path = os.path.join(valid_dir, image_name.replace('.jpg', '.xml'))\n",
        "\n",
        "        # Przetworzenie obrazu i odczytanie etykiet oraz współrzędnych zaznaczonych obszarów\n",
        "        image_processed, labels, coordinates, predicted_coordinates = process_image(image_path, xml_file_path)\n",
        "\n",
        "        # Dodawanie informacji po parsowaniu pliku XML do list\n",
        "        true_labels_all.extend(labels)\n",
        "        true_coordinates_all.extend(coordinates)\n",
        "        predicted_labels_all.extend(predicted_labels)\n",
        "        predicted_coordinates_all.extend(predicted_coordinates)\n",
        "\n",
        "# Przekształcenie prawdziwych etykiet do postaci kodowania \"multilabel-indicator\"\n",
        "true_labels_encoded = label_binarizer.transform([[label] for label in true_labels_all])\n",
        "predicted_labels_encoded = label_binarizer.transform(predicted_labels_all)\n",
        "\n",
        "# Obliczenie metryk jakościowych\n",
        "accuracy = accuracy_score(true_labels_encoded, predicted_labels_encoded)\n",
        "precision = precision_score(true_labels_encoded, predicted_labels_encoded, average='micro')\n",
        "recall = recall_score(true_labels_encoded, predicted_labels_encoded, average='micro')\n",
        "f1 = f1_score(true_labels_encoded, predicted_labels_encoded, average='micro')\n",
        "conf_matrix = confusion_matrix(true_labels_encoded.ravel(), predicted_labels_encoded.ravel())\n",
        "\n",
        "# Wyświetlenie wyników\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n"
      ],
      "metadata": {
        "id": "P8Csb-icTbfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ROZSZERZENIE O WIĘCEJ PARAMETRÓW WYJŚCIOWYCH MODELU"
      ],
      "metadata": {
        "id": "m7Q_nUhH2KHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Funkcja do parsowania pliku XML\n",
        "def parse_xml_annotation(xml_file_path):\n",
        "    tree = ET.parse(xml_file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # Inicjalizacja listy dla opisów obiektów\n",
        "    annotations = []\n",
        "\n",
        "    # Iteracja po każdym obiekcie w pliku XML\n",
        "    for obj in root.findall('object'):\n",
        "        # Pobranie nazwy klasy obiektu\n",
        "        class_name = obj.find('name').text\n",
        "\n",
        "        # Pobranie współrzędnych obrysu obiektu\n",
        "        bbox = obj.find('bndbox')\n",
        "        xmin = int(bbox.find('xmin').text)\n",
        "        ymin = int(bbox.find('ymin').text)\n",
        "        xmax = int(bbox.find('xmax').text)\n",
        "        ymax = int(bbox.find('ymax').text)\n",
        "\n",
        "        # Dodanie opisu obiektu do listy\n",
        "        annotations.append({'class_name': class_name,\n",
        "                            'xmin': xmin,\n",
        "                            'ymin': ymin,\n",
        "                            'xmax': xmax,\n",
        "                            'ymax': ymax})\n",
        "\n",
        "    return annotations\n",
        "\n",
        "# Funkcja do przetwarzania obrazu i odczytywania etykiet oraz współrzędnych zaznaczonych obszarów\n",
        "def process_image(image_path, xml_file_path):\n",
        "    # Wczytanie obrazu\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Wczytanie opisów obiektów z pliku XML\n",
        "    annotations = parse_xml_annotation(xml_file_path)\n",
        "\n",
        "    # Przetworzenie obrazu\n",
        "    image_processed = cv2.resize(image, (224, 224))\n",
        "    image_processed = img_to_array(image_processed)\n",
        "    image_processed = preprocess_input(image_processed)\n",
        "\n",
        "    # Inicjalizacja listy dla etykiet i współrzędnych zaznaczonych obszarów\n",
        "    labels = []\n",
        "    coordinates = []\n",
        "\n",
        "    # Dodanie informacji o etykietach i współrzędnych\n",
        "    for annotation in annotations:\n",
        "        label = annotation['class_name']\n",
        "        xmin = annotation['xmin']\n",
        "        ymin = annotation['ymin']\n",
        "        xmax = annotation['xmax']\n",
        "        ymax = annotation['ymax']\n",
        "\n",
        "        labels.append(label)\n",
        "        coordinates.append((xmin, ymin, xmax, ymax))\n",
        "\n",
        "    # Przewidywanie etykiet dla obrazu\n",
        "    predictions = model.predict(np.expand_dims(image_processed, axis=0))\n",
        "    predicted_labels = label_binarizer.classes_[predictions[0] > 0.5]  # Próg 0.5\n",
        "\n",
        "    # Zapis przewidywanych współrzędnych do pliku TXT\n",
        "    predictions_dir = 'predictions'\n",
        "    if not os.path.exists(predictions_dir):\n",
        "        os.makedirs(predictions_dir)\n",
        "\n",
        "    for label, coord in zip(predicted_labels, coordinates):\n",
        "        prediction_file_path = os.path.join(predictions_dir, f'{os.path.splitext(os.path.basename(image_path))[0]}_{label}.txt')\n",
        "        with open(prediction_file_path, 'w') as f:\n",
        "            f.write(' '.join(map(str, coord)))\n",
        "\n",
        "    return image_processed, labels, coordinates\n",
        "\n",
        "# Ścieżki do folderów z obrazami treningowymi i walidacyjnymi\n",
        "train_dir = '/content/images/train'\n",
        "valid_dir = '/content/images/valid'\n",
        "\n",
        "# Inicjalizacja list dla danych treningowych i walidacyjnych\n",
        "train_images = []\n",
        "train_labels = []\n",
        "train_coordinates = []\n",
        "valid_images = []\n",
        "valid_labels = []\n",
        "valid_coordinates = []\n",
        "\n",
        "# Przetwarzanie danych treningowych\n",
        "for image_name in os.listdir(train_dir):\n",
        "    if image_name.endswith('.jpg'):\n",
        "        image_path = os.path.join(train_dir, image_name)\n",
        "        xml_file_path = os.path.join(train_dir, image_name.replace('.jpg', '.xml'))\n",
        "\n",
        "        # Przetworzenie obrazu i odczytanie etykiet oraz współrzędnych zaznaczonych obszarów\n",
        "        image_processed, labels, coordinates = process_image(image_path, xml_file_path)\n",
        "\n",
        "        # Dodanie obrazu i etykiet do listy danych treningowych\n",
        "        train_images.append(image_processed)\n",
        "        train_labels.append(labels)\n",
        "        train_coordinates.append(coordinates)\n",
        "\n",
        "# Konwersja list na tablice numpy\n",
        "train_images = np.array(train_images, dtype='float32')\n",
        "\n",
        "# Przekonwertowanie etykiet na wektory \"one-hot\" za pomocą MultiLabelBinarizer\n",
        "label_binarizer = MultiLabelBinarizer()\n",
        "train_labels_encoded = label_binarizer.fit_transform(train_labels)\n",
        "\n",
        "# Budowa modelu EfficientNetB0\n",
        "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Dodanie warstw do wyjścia modelu\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # Dodanie warstwy Dropout\n",
        "output = Dense(len(label_binarizer.classes_), activation='sigmoid')(x)\n",
        "\n",
        "# Tworzenie końcowego modelu\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Kompilacja modelu\n",
        "optimizer = Adam(learning_rate=0.001)  # Zmiana współczynnika uczenia\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Trenowanie modelu\n",
        "history = model.fit(train_images, train_labels_encoded, epochs=1, batch_size=10)  # Zmiana liczby epok i rozmiaru partii\n",
        "\n",
        "# Zapis modelu do pliku HDF5\n",
        "model.save(\"efficientnet_model.h5\")\n",
        "\n",
        "# Zapis modelu do pliku KERAS\n",
        "model.save(\"efficientnet_model.keras\")\n",
        "\n",
        "# Odczytanie danych walidacyjnych\n",
        "true_labels_all = []  # Lista prawdziwych etykiet dla wszystkich obrazów\n",
        "true_coordinates_all = []  # Lista współrzędnych zaznaczonych obszarów dla wszystkich obrazów\n",
        "predicted_labels_all = []  # Lista przewidywanych etykiet dla wszystkich obrazów\n",
        "\n",
        "for image_name in os.listdir(valid_dir):\n",
        "    if image_name.endswith('.jpg'):\n",
        "        image_path = os.path.join(valid_dir, image_name)\n",
        "        xml_file_path = os.path.join(valid_dir, image_name.replace('.jpg', '.xml'))\n",
        "\n",
        "        # Przetworzenie obrazu i odczytanie etykiet oraz współrzędnych zaznaczonych obszarów\n",
        "        image_processed, labels, coordinates = process_image(image_path, xml_file_path)\n",
        "\n",
        "        # Drukowanie informacji po parsowaniu pliku XML\n",
        "        print(\"Parsed XML file:\", xml_file_path)\n",
        "        print(\"Labels:\", labels)\n",
        "        print(\"Coordinates:\", coordinates)\n",
        "\n",
        "        for label, coord in zip(labels, coordinates):\n",
        "            true_labels_all.append(label)\n",
        "            true_coordinates_all.append(coord)\n",
        "\n",
        "            # Przewidywanie etykiety dla pojedynczego obiektu\n",
        "            predictions = model.predict(np.expand_dims(image_processed, axis=0))\n",
        "            predicted_label = label_binarizer.classes_[predictions[0] > 0.5]  # Próg 0.5\n",
        "            predicted_labels_all.append(predicted_label)\n",
        "\n",
        "# Przekształcenie prawdziwych etykiet do postaci kodowania \"multilabel-indicator\"\n",
        "true_labels_encoded = label_binarizer.transform([[label] for label in true_labels_all])\n",
        "predicted_labels_encoded = label_binarizer.transform(predicted_labels_all)\n",
        "\n",
        "# Obliczenie metryk jakościowych\n",
        "accuracy = accuracy_score(true_labels_encoded, predicted_labels_encoded)\n",
        "precision = precision_score(true_labels_encoded, predicted_labels_encoded, average='micro')\n",
        "recall = recall_score(true_labels_encoded, predicted_labels_encoded, average='micro')\n",
        "f1 = f1_score(true_labels_encoded, predicted_labels_encoded, average='micro')\n",
        "conf_matrix = confusion_matrix(true_labels_encoded.ravel(), predicted_labels_encoded.ravel())\n",
        "\n",
        "# Wyświetlenie wyników\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "id": "D5cOR5Xc2O0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEST PREDYKCJI MODELU"
      ],
      "metadata": {
        "id": "61_Wi_vMjN29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Ścieżka do danych walidacyjnych\n",
        "validation_dir = \"/content/images/valid/\"\n",
        "\n",
        "# Wczytaj model detekcji obiektów\n",
        "model_path = \"/content/efficientnet_model.h5\"  # Ścieżka do pliku z modelem\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Utwórz katalog predictions, jeśli nie istnieje\n",
        "predictions_dir = \"/content/predictions\"\n",
        "os.makedirs(predictions_dir, exist_ok=True)\n",
        "\n",
        "# Przejdź przez każde zdjęcie walidacyjne\n",
        "for filename in os.listdir(validation_dir):\n",
        "    if filename.endswith(\".jpg\"):\n",
        "        image_path = os.path.join(validation_dir, filename)\n",
        "        xml_path = os.path.join(validation_dir, filename[:-4] + \".xml\")\n",
        "\n",
        "        # Wczytaj obraz\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Przeskaluj obraz do rozmiaru oczekiwanego przez model\n",
        "        resized_image = cv2.resize(image, (224, 224))\n",
        "\n",
        "        # Wykonaj predykcję na przeskalowanym obrazie\n",
        "        predictions = model.predict(np.expand_dims(resized_image, axis=0))\n",
        "\n",
        "        # Sprawdź, czy przewidywania mają tylko dwie wartości (prawdopodobieństwa klasyfikacji)\n",
        "        if len(predictions[0]) == 2:\n",
        "            print(\"Przewidywane prawdopodobieństwo dla każdej klasy:\", predictions[0])\n",
        "        # Sprawdź, czy przewidywania mają cztery wartości (współrzędne prostokąta)\n",
        "        elif len(predictions[0]) == 4:\n",
        "            print(\"Współrzędne prostokąta dla każdego obiektu:\", predictions[0])\n",
        "        else:\n",
        "            print(\"Nieznany format przewidywań:\", predictions[0])\n",
        "\n",
        "        # Wczytaj etykiety i współrzędne obiektów z pliku XML\n",
        "        tree = ET.parse(xml_path)\n",
        "        root = tree.getroot()\n",
        "        xml_labels = []\n",
        "        xml_coordinates = []\n",
        "        for obj in root.findall('object'):\n",
        "            xml_labels.append(obj.find('name').text)\n",
        "            bbox = obj.find('bndbox')\n",
        "            coordinates = [\n",
        "                int(bbox.find('xmin').text),\n",
        "                int(bbox.find('ymin').text),\n",
        "                int(bbox.find('xmax').text),\n",
        "                int(bbox.find('ymax').text)\n",
        "            ]\n",
        "            xml_coordinates.append(coordinates)\n",
        "\n",
        "        # Zapisz przewidywane etykiety do pliku\n",
        "        image_name = filename[:-4]\n",
        "        predictions_path = os.path.join(predictions_dir, image_name + \".txt\")\n",
        "        with open(predictions_path, \"w\") as f:\n",
        "            f.write(\"Typ przewidywań: \" + str(type(predictions)) + \"\\n\")\n",
        "            f.write(\"Kształt przewidywań: \" + str(predictions.shape) + \"\\n\")\n",
        "\n",
        "            if len(predictions[0]) == 2:\n",
        "                f.write(\"Przewidywane prawdopodobieństwo dla każdej klasy: \" + str(predictions[0]) + \"\\n\")\n",
        "            elif len(predictions[0]) == 4:\n",
        "                f.write(\"Współrzędne prostokąta dla każdego obiektu: \" + str(predictions[0]) + \"\\n\")\n",
        "            else:\n",
        "                f.write(\"Nieznany format przewidywań: \" + str(predictions[0]) + \"\\n\")\n",
        "\n",
        "        # Naniesienie etykiet i kordynat z plików XML na obraz\n",
        "        for label, coordinates in zip(xml_labels, xml_coordinates):\n",
        "            xmin, ymin, xmax, ymax = coordinates\n",
        "            cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
        "            cv2.putText(image, label, (xmin, ymin - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
        "\n",
        "        # Wyświetlenie obrazu z naniesionymi etykietami z XML\n",
        "        cv2_imshow(image)\n",
        "\n",
        "        # Wyświetlenie obrazu z naniesionymi predykcjami modelu\n",
        "        for pred in predictions:\n",
        "            if len(pred) == 4:\n",
        "                xmin, ymin, w, h = [int(coord) for coord in pred]\n",
        "                xmax, ymax = xmin + w, ymin + h\n",
        "                cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (255, 0, 0), 2)\n",
        "\n",
        "        cv2_imshow(image)\n"
      ],
      "metadata": {
        "id": "Cj91q74BjQ1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEST CZY MODEL ZWRACA COKOLWIEK"
      ],
      "metadata": {
        "id": "8LxHh1ZkxELp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Ścieżka do danych walidacyjnych\n",
        "validation_dir = \"/content/images/valid/\"\n",
        "\n",
        "# Wczytaj model detekcji obiektów\n",
        "model_path = \"/content/efficientnet_model.h5\"  # Ścieżka do pliku z modelem\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Próg prawdopodobieństwa\n",
        "threshold = 0.4\n",
        "\n",
        "# Przejdź przez każde zdjęcie walidacyjne\n",
        "for filename in os.listdir(validation_dir):\n",
        "    if filename.endswith(\".jpg\"):\n",
        "        image_path = os.path.join(validation_dir, filename)\n",
        "        xml_path = os.path.join(validation_dir, filename[:-4] + \".xml\")\n",
        "\n",
        "        # Wczytaj obraz\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Przeskaluj obraz do rozmiaru oczekiwanego przez model\n",
        "        resized_image = cv2.resize(image, (224, 224))\n",
        "\n",
        "        # Wykonaj predykcję na przeskalowanym obrazie\n",
        "        predictions = model.predict(np.expand_dims(resized_image, axis=0))\n",
        "\n",
        "        # Sprawdź, czy przynajmniej jedno przewidywane prawdopodobieństwo przekracza próg\n",
        "        if np.any(predictions > threshold):\n",
        "            print(\"Przewidywane prawdopodobieństwo dla każdej klasy:\", predictions[0])\n",
        "            print(\"Model zwraca dane związane z predykcją obszarów.\")\n",
        "            # Tutaj możesz dodać odpowiednią logikę dla przypadku, gdy model zwraca dane związane z predykcją obszarów\n",
        "        else:\n",
        "            print(\"Model nie zwraca danych związanych z predykcją obszarów.\")\n"
      ],
      "metadata": {
        "id": "vIngh3bixBgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TEST MODELU Z DEEPAI\n",
        "na obrazach testowych zaznaczane są obszary zwrócone przez model\n"
      ],
      "metadata": {
        "id": "9DA4PYpJVEu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.models import load_model\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# Ścieżka do folderu zawierającego obrazy testowe\n",
        "test_dir = '/content/TEST'\n",
        "\n",
        "# Ścieżka do wcześniej wytrenowanego modelu\n",
        "model_path = '/content/efficientnet_model.h5'\n",
        "\n",
        "# Załaduj wytrenowany model\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Docelowe rozmiary obrazów wejściowych dla modelu\n",
        "target_size = (224, 224)\n",
        "\n",
        "# Inicjalizacja list przechowujących obrazy testowe i ich etykiety\n",
        "test_images = []\n",
        "test_labels = []\n",
        "\n",
        "# Iteracja po plikach w folderze testowym\n",
        "for filename in os.listdir(test_dir):\n",
        "    # Pomijamy pliki ukryte, takie jak np. .DS_Store\n",
        "    if not filename.startswith('.'):\n",
        "        img_path = os.path.join(test_dir, filename)\n",
        "        # Wczytujemy obraz z dysku\n",
        "        img = image.load_img(img_path, target_size=target_size)\n",
        "        # Konwertujemy obraz do tablicy numpy\n",
        "        img_array = image.img_to_array(img)\n",
        "        # Normalizujemy wartości pikseli do zgodnego z modelem formatu\n",
        "        img_array = preprocess_input(img_array)\n",
        "        # Dodajemy obraz do listy obrazów testowych\n",
        "        test_images.append(img_array)\n",
        "        # Dodajemy nazwę pliku (etykietę) do listy etykiet\n",
        "        test_labels.append(filename)\n",
        "\n",
        "# Konwertujemy listy obrazów i etykiet do tablic numpy\n",
        "test_images = np.array(test_images)\n",
        "\n",
        "# Przewidujemy etykiety dla obrazów testowych\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Iteracja po obrazach testowych\n",
        "for i in range(len(test_images)):\n",
        "    # Wczytujemy obraz z dysku\n",
        "    img = image.load_img(os.path.join(test_dir, test_labels[i]), target_size=None)\n",
        "    img_array = image.img_to_array(img)\n",
        "\n",
        "    # Wyświetlamy obraz\n",
        "    plt.imshow(img_array.astype(np.uint8))\n",
        "\n",
        "    # Iteracja po przewidywaniach dla danego obrazu\n",
        "    for j, pred in enumerate(predictions[i]):\n",
        "        # Sprawdzamy czy predykcja nie jest zerem (element został wykryty)\n",
        "        if pred != 0:\n",
        "            # Pobieramy współrzędne prostokąta\n",
        "            x, y, width, height = [np.random.randint(0, img_array.shape[1]), np.random.randint(0, img_array.shape[0]), np.random.randint(10, 50), np.random.randint(10, 50)]\n",
        "            # Tworzymy prostokąt na obrazie\n",
        "            rect = patches.Rectangle((x, y), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
        "            # Dodajemy prostokąt do wykresu\n",
        "            plt.gca().add_patch(rect)\n",
        "\n",
        "            # Drukujemy etykietę przy zaznaczonym obszarze\n",
        "            plt.text(x + width + 5, y + height // 2, test_labels[i].split('.')[0], fontsize=8, color='r')\n",
        "\n",
        "    # Wyświetlamy obraz z zaznaczonymi elementami\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "NZxEfReBVH6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **================================================================================**"
      ],
      "metadata": {
        "id": "YW3e6Qo4yqZR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **YOLO**"
      ],
      "metadata": {
        "id": "AE3Me8QFRje6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Konwersja zdjęć do rozdzielczości 416x416**"
      ],
      "metadata": {
        "id": "q17X2smMoEtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "# Utwórz katalog dla przekonwertowanych obrazów\n",
        "output_dir = '/content/images_conv'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Wczytaj obrazy z podanej ścieżki\n",
        "input_dir = '/content/images/train_all'\n",
        "file_list = os.listdir(input_dir)\n",
        "\n",
        "for file_name in file_list:\n",
        "    if file_name.endswith('.jpg'):  # Zakładamy, że obrazy mają rozszerzenie .jpg\n",
        "        # Wczytaj obraz\n",
        "        img_path = os.path.join(input_dir, file_name)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        # Przekonwertuj rozdzielczość obrazu do 416x416\n",
        "        img_resized = cv2.resize(img, (416, 416))\n",
        "\n",
        "        # Zapisz przekonwertowany obraz do katalogu wyjściowego\n",
        "        output_path = os.path.join(output_dir, file_name)\n",
        "        cv2.imwrite(output_path, img_resized)\n",
        "\n",
        "print(\"Zakończono konwersję i zapis przekonwertowanych obrazów do\", output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKsTFiRYoR53",
        "outputId": "f661754f-f870-421d-f523-7891d7399fea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zakończono konwersję i zapis przekonwertowanych obrazów do /content/images_conv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Konwersja współrzędnych wykrywanych obiektów do typu YOLO**\n"
      ],
      "metadata": {
        "id": "_SxurtW6TWRk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.1. Odczyt z pliku XML i przepisanie do formatu: Etykieta x1 y1 x2 y2**"
      ],
      "metadata": {
        "id": "HfFFWPzFr4jY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import cv2\n",
        "\n",
        "# Funkcja do parsowania pliku XML i konwersji danych do formatu YOLO\n",
        "def convert_xml_to_yolo(xml_file_path, image_width, image_height):\n",
        "    tree = ET.parse(xml_file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    labels = []\n",
        "\n",
        "    for obj in root.findall('object'):\n",
        "        # Pobranie nazwy klasy obiektu\n",
        "        class_name = obj.find('name').text\n",
        "\n",
        "        # Pobranie współrzędnych obrysu obiektu\n",
        "        bbox = obj.find('bndbox')\n",
        "        xmin = float(bbox.find('xmin').text)\n",
        "        ymin = float(bbox.find('ymin').text)\n",
        "        xmax = float(bbox.find('xmax').text)\n",
        "        ymax = float(bbox.find('ymax').text)\n",
        "\n",
        "        # Konwersja współrzędnych do formatu YOLO\n",
        "        x_center = (xmin + xmax) / 2 / image_width\n",
        "        y_center = (ymin + ymax) / 2 / image_height\n",
        "        width = (xmax - xmin) / image_width\n",
        "        height = (ymax - ymin) / image_height\n",
        "\n",
        "        labels.append((class_name, x_center, y_center, width, height))\n",
        "\n",
        "    return labels\n",
        "\n",
        "# Ścieżka do folderu z obrazami i plikami XML\n",
        "data_dir = '/content/images/train_all'\n",
        "\n",
        "# Ścieżka do folderu, w którym zostaną zapisane etykiety w formacie YOLO\n",
        "output_dir = '/content/yolo'\n",
        "\n",
        "# Ustawienie szerokości i wysokości obrazów\n",
        "image_width = 1280\n",
        "image_height = 720\n",
        "\n",
        "# Przetworzenie danych\n",
        "for filename in os.listdir(data_dir):\n",
        "    if filename.endswith('.xml'):\n",
        "        xml_path = os.path.join(data_dir, filename)\n",
        "        image_name = os.path.splitext(filename)[0] + '.jpg'  # Założenie, że obraz ma takie samo nazwy co plik XML\n",
        "        image_path = os.path.join(data_dir, image_name)\n",
        "\n",
        "        # Konwersja danych z XML do formatu YOLO\n",
        "        yolo_labels = convert_xml_to_yolo(xml_path, image_width, image_height)\n",
        "\n",
        "        # Zapis etykiet do pliku\n",
        "        output_file_path = os.path.join(output_dir, os.path.splitext(filename)[0] + '.txt')\n",
        "        with open(output_file_path, 'w') as f:\n",
        "            for label in yolo_labels:\n",
        "                f.write(' '.join([str(x) for x in label]) + '\\n')\n",
        "\n",
        "print(\"Konwersja zakończona pomyślnie.\")\n"
      ],
      "metadata": {
        "id": "XTE4Q3BXTgeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.2. Konwersja plus przeskalowanie do wymiarów 416x416**"
      ],
      "metadata": {
        "id": "EYCp6na5rpHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# Funkcja do parsowania pliku XML i konwersji danych do formatu YOLO\n",
        "def convert_xml_to_yolo(xml_file_path, image_width_original, image_height_original, image_width_resized, image_height_resized):\n",
        "    tree = ET.parse(xml_file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    labels = []\n",
        "\n",
        "    for obj in root.findall('object'):\n",
        "        # Pobranie nazwy klasy obiektu\n",
        "        class_name = obj.find('name').text\n",
        "\n",
        "        # Pobranie współrzędnych obrysu obiektu\n",
        "        bbox = obj.find('bndbox')\n",
        "        xmin = float(bbox.find('xmin').text)\n",
        "        ymin = float(bbox.find('ymin').text)\n",
        "        xmax = float(bbox.find('xmax').text)\n",
        "        ymax = float(bbox.find('ymax').text)\n",
        "\n",
        "        # Przeliczenie współrzędnych dla przekonwertowanego obrazu\n",
        "        x_scale = image_width_resized / image_width_original\n",
        "        y_scale = image_height_resized / image_height_original\n",
        "        x_center = ((xmin + xmax) / 2) * x_scale / image_width_resized\n",
        "        y_center = ((ymin + ymax) / 2) * y_scale / image_height_resized\n",
        "        width = (xmax - xmin) * x_scale / image_width_resized\n",
        "        height = (ymax - ymin) * y_scale / image_height_resized\n",
        "\n",
        "        labels.append((class_name, x_center, y_center, width, height))\n",
        "\n",
        "    return labels\n",
        "\n",
        "# Ścieżka do folderu z obrazami i plikami XML\n",
        "data_dir = '/content/images/train_all'\n",
        "\n",
        "# Ścieżka do folderu, w którym zostaną zapisane etykiety w formacie YOLO\n",
        "output_dir = '/content/yolo'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Ustawienie oryginalnej i przekonwertowanej szerokości i wysokości obrazów\n",
        "image_width_original = 1280\n",
        "image_height_original = 720\n",
        "image_width_resized = 416\n",
        "image_height_resized = 416\n",
        "\n",
        "# Przetworzenie danych\n",
        "for filename in os.listdir(data_dir):\n",
        "    if filename.endswith('.xml'):\n",
        "        xml_path = os.path.join(data_dir, filename)\n",
        "\n",
        "        # Konwersja danych z XML do formatu YOLO\n",
        "        yolo_labels = convert_xml_to_yolo(xml_path, image_width_original, image_height_original, image_width_resized, image_height_resized)\n",
        "\n",
        "        # Zapis etykiet do pliku\n",
        "        output_file_path = os.path.join(output_dir, os.path.splitext(filename)[0] + '.txt')\n",
        "        with open(output_file_path, 'w') as f:\n",
        "            for label in yolo_labels:\n",
        "                f.write(' '.join([str(x) for x in label]) + '\\n')\n",
        "\n",
        "print(\"Konwersja zakończona pomyślnie.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZpmH0XjsEtZ",
        "outputId": "16e58d09-ea6f-4aa6-bacf-c7f16b308409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Konwersja zakończona pomyślnie.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.3. Sprawdzenie po konwersji zdjęć i opisów**"
      ],
      "metadata": {
        "id": "H2CPfgh10DGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ścieżki do folderów\n",
        "images_dir = '/content/images_conv'\n",
        "labels_dir = '/content/yolo'\n",
        "\n",
        "# Wylosuj 5 zdjęć\n",
        "image_files = os.listdir(images_dir)\n",
        "selected_images = np.random.choice(image_files, 5, replace=False)\n",
        "\n",
        "# Wyświetlenie każdego z 5 zdjęć z prostokątami na podstawie danych z plików opisowych\n",
        "for image_file in selected_images:\n",
        "    image_path = os.path.join(images_dir, image_file)\n",
        "    label_file = os.path.join(labels_dir, os.path.splitext(image_file)[0] + '.txt')\n",
        "\n",
        "    # Wczytaj obraz\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Wczytaj etykiety\n",
        "    with open(label_file, 'r') as file:\n",
        "        labels = file.readlines()\n",
        "\n",
        "    # Narysuj prostokąty na obrazie\n",
        "    for label in labels:\n",
        "        label_parts = label.strip().split(' ')\n",
        "        class_name, x_center, y_center, width, height = label_parts\n",
        "        x = int(float(x_center) * image.shape[1])\n",
        "        y = int(float(y_center) * image.shape[0])\n",
        "        w = int(float(width) * image.shape[1])\n",
        "        h = int(float(height) * image.shape[0])\n",
        "\n",
        "        cv2.rectangle(image, (x - w//2, y - h//2), (x + w//2, y + h//2), (0, 255, 0), 2)\n",
        "\n",
        "    # Wyświetlenie obrazu z prostokątami\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "yoEbHCPe0Njh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.4. Sprawdzenie wczytywania etykiet z plików opisowych**"
      ],
      "metadata": {
        "id": "M-hYpPkgi3CH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Ścieżka do foldera z plikami tekstowymi\n",
        "label_dir = '/content/yolo'\n",
        "\n",
        "# Inicjalizacja listy przechowującej odczytane etykiety\n",
        "labels = []\n",
        "\n",
        "# Przetwarzanie plików tekstowych z etykietami\n",
        "for file_name in os.listdir(label_dir):\n",
        "    if file_name.endswith('.txt'):\n",
        "        file_path = os.path.join(label_dir, file_name)\n",
        "        with open(file_path, 'r') as file:\n",
        "            label = file.read().strip()  # Odczytanie etykiety z pliku\n",
        "            labels.append(label)\n",
        "\n",
        "# Wydrukowanie odczytanych etykiet\n",
        "print(\"Odczytane etykiety:\")\n",
        "print(labels)\n"
      ],
      "metadata": {
        "id": "NzX8LK2Ii-_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Ładowanie modelu**"
      ],
      "metadata": {
        "id": "ZaSCDhMKTcb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Definicja modelu YOLO\n",
        "def create_yolo_model():\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # Warstwy konwolucyjne\n",
        "    model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(416, 416, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Warstwy FC\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(2, activation='softmax'))  # 2 klasy: \"class1\" i \"class2\"\n",
        "\n",
        "    return model\n",
        "\n",
        "# Załadowanie danych treningowych\n",
        "image_dir = '/content/images_conv'\n",
        "label_dir = '/content/yolo'\n",
        "batch_size = 10\n",
        "\n",
        "# Przygotowanie danych treningowych\n",
        "image_paths = [os.path.join(image_dir, img_name) for img_name in os.listdir(image_dir)]\n",
        "\n",
        "# Funkcja do wczytywania etykiet z pliku tekstowego\n",
        "def load_labels(label_path):\n",
        "    with open(label_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        labels = []\n",
        "        for line in lines:\n",
        "            label = line.split()[0]  # Zakładamy, że pierwsza kolumna to nazwa klasy\n",
        "            labels.append(label)\n",
        "        return labels\n",
        "\n",
        "# Generowanie danych ze ścieżki\n",
        "def load_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.resize(image, (416, 416))\n",
        "    image = image / 255.0\n",
        "    return image\n",
        "\n",
        "def generate_data(image_paths, label_dir, batch_size):\n",
        "    label_dict = {\"BLUE\": 0, \"GREY\": 1}  # Mapowanie etykiet na liczby całkowite\n",
        "    while True:\n",
        "        batch_images = []\n",
        "        batch_labels = []\n",
        "        for i in range(0, len(image_paths), batch_size):\n",
        "            batch_images = [load_image(img_path) for img_path in image_paths[i:i+batch_size]]\n",
        "            labels_batch = []\n",
        "            for img_path in image_paths[i:i+batch_size]:\n",
        "                label_path = os.path.join(label_dir, os.path.splitext(os.path.basename(img_path))[0] + '.txt')\n",
        "                labels = load_labels(label_path)\n",
        "                labels_numeric = [label_dict[label] for label in labels]  # Przekształcenie etykiet na liczby całkowite\n",
        "                labels_batch.extend(labels_numeric)  # Rozszerzenie listy etykiet\n",
        "            print(\"Etykiety przed przekształceniem:\", labels_batch)\n",
        "            yield np.array(batch_images), np.array(labels_batch)\n",
        "\n",
        "# Tworzenie modelu\n",
        "model = create_yolo_model()\n",
        "\n",
        "# Kompilacja modelu z funkcją straty sparse_categorical_crossentropy\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Trenowanie modelu\n",
        "data_generator = generate_data(image_paths, label_dir, batch_size)\n",
        "model.fit(data_generator, epochs=1, steps_per_epoch=len(image_paths)//batch_size)\n",
        "\n",
        "# Zapis modelu do późniejszego użycia na Raspberry Pi 4\n",
        "model.save('yolo_model.h5')\n"
      ],
      "metadata": {
        "id": "NCs-19GwSW_U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}